{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import copy \n",
    "import math \n",
    "from utils import get_smi_list, replace_atom, get_dic, encode_smi, pad_smi, clones, parallel_f, pad, normalize, get_atom_pos, MyDataset, subsequent_mask\n",
    "from model import Encoder, Decoder, device\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tgt_mask(target) :\n",
    "    mask = (target != 0).unsqueeze(-2) \n",
    "    mask = mask & subsequent_mask(target.size(-1)) \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tgt_mask(target) :\n",
    "    mask = torch.empty(0) \n",
    "    for i in range(1, target.size(1) + 1) :\n",
    "        temp = torch.clone(target)\n",
    "        temp[:, i:, :] = False\n",
    "        temp = temp.unsqueeze(1)\n",
    "        mask = torch.cat((mask, temp), dim = 1)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1734, -1.5940, -0.2606, -0.8086,  0.1455]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1734, -1.5940, -0.2606, -0.8086,  0.1455],\n",
       "         [ 0.1734, -1.5940, -0.2606, -0.8086,  0.1455],\n",
       "         [ 0.1734, -1.5940, -0.2606, -0.8086,  0.1455],\n",
       "         [ 0.1734, -1.5940, -0.2606, -0.8086,  0.1455],\n",
       "         [ 0.1734, -1.5940, -0.2606, -0.8086,  0.1455]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randn(1, 1, 5) \n",
    "print(target)\n",
    "target.repeat(1, 5, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: tensor([[[-1.1767,  2.7450, -0.8661],\n",
      "         [-0.1688, -2.3080,  1.0370],\n",
      "         [-0.9792, -1.4364,  0.3771],\n",
      "         [ 0.4365,  0.6331, -0.4206],\n",
      "         [-0.2603,  1.2520, -0.8751]]])\n",
      "target: tensor([[[-0.1688, -2.3080,  1.0370],\n",
      "         [-0.9792, -1.4364,  0.3771],\n",
      "         [ 0.4365,  0.6331, -0.4206],\n",
      "         [-0.2603,  1.2520, -0.8751]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True, False, False],\n",
       "          [ True,  True, False],\n",
       "          [ True,  True,  True]],\n",
       "\n",
       "         [[ True, False, False],\n",
       "          [ True,  True, False],\n",
       "          [ True,  True,  True]],\n",
       "\n",
       "         [[ True, False, False],\n",
       "          [ True,  True, False],\n",
       "          [ True,  True,  True]],\n",
       "\n",
       "         [[ True, False, False],\n",
       "          [ True,  True, False],\n",
       "          [ True,  True,  True]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randn(1, 5, 3)\n",
    "print(f'target: {target}')\n",
    "target = target[:, 1:, :]\n",
    "print(f'target: {target}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:29:17] UFFTYPER: Unrecognized atom type: Ba (0)\n"
     ]
    }
   ],
   "source": [
    "smi_list = get_smi_list('data/ADAGRASIB_SMILES.txt')\n",
    "\n",
    "coor_list = parallel_f(get_atom_pos, smi_list)\n",
    "longest_coor = len(max(coor_list, key = len))\n",
    "coor_list = [pad(normalize(c), longest_coor) for c in coor_list]\n",
    "\n",
    "smi_list = [replace_atom(smi) for smi in smi_list]\n",
    "smi_dic = get_dic(smi_list)\n",
    "smint_list = [encode_smi(smi, smi_dic) for smi in smi_list]\n",
    "longest_smint = len(max(smint_list, key = len))\n",
    "smint_list = [pad_smi(smint, longest_smint, smi_dic) for smint in smint_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "dataset = MyDataset(smint_list, coor_list)\n",
    "train_set, val_set, test_set = random_split(dataset, [0.9, 0.05, 0.05])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader(val_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module) :\n",
    "    def __init__(self, dim_model, num_head, dropout, longest_coor) :\n",
    "        super (DecoderLayer, self).__init__()\n",
    "        self.dim_model = dim_model\n",
    "        self.longest_coor = longest_coor\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(dim_model) \n",
    "        self.self_attn = TargetAttention(dim_model, num_head, longest_coor)\n",
    "        self.drop1 = nn.Dropout(dropout) \n",
    "\n",
    "        self.norm2 = nn.LayerNorm(dim_model)\n",
    "        self.cross_attn = SourceAttention(dim_model, num_head)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.norm3 = nn.LayerNorm(dim_model)\n",
    "        self.feed_foward = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(dim_model, dim_model),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.drop3 = nn.Dropout(dropout) \n",
    "\n",
    "\n",
    "    def forward(self, memory, target) : \n",
    "        target = target[]\n",
    "        mask = get_tgt_mask(target).unsqueeze(1) \n",
    "\n",
    "        \n",
    "        \n",
    "        return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: tensor([[-0.6757, -0.6612,  0.5823, -0.2785, -1.0716, -0.0079,  0.8986,  0.6482,\n",
      "         -2.0828,  0.2412],\n",
      "        [-0.4615,  0.5928,  1.1354, -0.5337,  0.2759, -0.5715,  1.7895,  0.1297,\n",
      "          0.6090, -0.1425]])\n",
      "mask: torch.Size([2, 1, 10]) \n",
      " tensor([[[True, True, True, True, True, True, True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True, True, True, True, True, True, True]]])\n",
      "mask: torch.Size([2, 10, 10]) \n",
      " tensor([[[ True, False, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[ True, False, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "target = torch.randn(2, 10) \n",
    "print(f'target: {target}')\n",
    "target_y = target[:, 1:] \n",
    "target_mask = (target != 2).unsqueeze(-2)\n",
    "print(f'mask: {target_mask.shape} \\n {target_mask}')\n",
    "\n",
    "target_mask = target_mask & subsequent_mask(target.size(-1))\n",
    "print(f'mask: {target_mask.shape} \\n {target_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: torch.Size([1, 22, 3])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "         [-1.0063, -0.1920, -0.9023],\n",
      "         [-0.7568, -0.4628, -2.0892],\n",
      "         [-2.4237, -0.0856, -0.5034],\n",
      "         [-2.7379,  0.1860,  0.6837],\n",
      "         [-3.4523, -0.2776, -1.4067],\n",
      "         [ 2.5194,  0.4745,  0.7282],\n",
      "         [ 1.7493,  0.4355, -0.4975],\n",
      "         [ 0.2908,  0.1984, -0.2122],\n",
      "         [-0.4396,  0.1725, -1.5517],\n",
      "         [-1.8369, -0.0568, -1.2456],\n",
      "         [-2.6100,  1.1284, -1.0383],\n",
      "         [-4.0329,  1.0158, -1.5066],\n",
      "         [-4.9130,  0.1504, -0.6993],\n",
      "         [-4.2698, -1.0023, -0.0136],\n",
      "         [-3.6355, -1.8918, -1.0662],\n",
      "         [-2.2077, -1.4289, -1.2024],\n",
      "         [-1.3145, -2.3092, -1.2802],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]])\n",
      "mask: torch.Size([1, 21, 3])\n",
      "tensor([[[-1.0063, -0.1920, -0.9023],\n",
      "         [-0.7568, -0.4628, -2.0892],\n",
      "         [-2.4237, -0.0856, -0.5034],\n",
      "         [-2.7379,  0.1860,  0.6837],\n",
      "         [-3.4523, -0.2776, -1.4067],\n",
      "         [ 2.5194,  0.4745,  0.7282],\n",
      "         [ 1.7493,  0.4355, -0.4975],\n",
      "         [ 0.2908,  0.1984, -0.2122],\n",
      "         [-0.4396,  0.1725, -1.5517],\n",
      "         [-1.8369, -0.0568, -1.2456],\n",
      "         [-2.6100,  1.1284, -1.0383],\n",
      "         [-4.0329,  1.0158, -1.5066],\n",
      "         [-4.9130,  0.1504, -0.6993],\n",
      "         [-4.2698, -1.0023, -0.0136],\n",
      "         [-3.6355, -1.8918, -1.0662],\n",
      "         [-2.2077, -1.4289, -1.2024],\n",
      "         [-1.3145, -2.3092, -1.2802],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "for input, target in train_loader :\n",
    "    mask = target[:, 1:, :]\n",
    "    print(f'mask: {mask.shape}')\n",
    "    print(mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_MODEL = 128 \n",
    "NUM_HEAD = 4\n",
    "NUM_LAYER = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "encoder = Encoder(DIM_MODEL, NUM_HEAD, NUM_LAYER, DROPOUT, len(smi_dic)).to(device)\n",
    "decoder = Decoder(DIM_MODEL, NUM_HEAD, NUM_LAYER, DROPOUT, longest_coor).to(device)\n",
    "\n",
    "loss_fn = nn.L1Loss() \n",
    "e_optim = torch.optim.Adam(encoder.parameters(), lr = 0.001)\n",
    "d_optim = torch.optim.Adam(decoder.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb0c6c4af8d46f193f59c18ac000a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Train Loss: 2.0436 -- Val Loss: 2.0880\n",
      "Epoch 2 -- Train Loss: 2.0373 -- Val Loss: 2.0287\n",
      "Epoch 3 -- Train Loss: 2.0409 -- Val Loss: 2.0511\n",
      "Epoch 4 -- Train Loss: 2.0313 -- Val Loss: 1.9991\n",
      "Epoch 5 -- Train Loss: 2.0358 -- Val Loss: 2.0412\n",
      "Epoch 6 -- Train Loss: 2.0342 -- Val Loss: 2.0823\n",
      "Epoch 7 -- Train Loss: 2.0382 -- Val Loss: 2.0728\n",
      "Epoch 8 -- Train Loss: 2.0333 -- Val Loss: 2.0106\n",
      "Epoch 9 -- Train Loss: 2.0365 -- Val Loss: 2.0457\n",
      "Epoch 10 -- Train Loss: 2.0330 -- Val Loss: 2.0265\n",
      "Epoch 11 -- Train Loss: 2.0350 -- Val Loss: 2.0276\n",
      "Epoch 12 -- Train Loss: 2.0320 -- Val Loss: 2.0140\n",
      "Epoch 13 -- Train Loss: 2.0287 -- Val Loss: 2.0551\n",
      "Epoch 14 -- Train Loss: 2.0217 -- Val Loss: 2.0372\n",
      "Epoch 15 -- Train Loss: 2.0318 -- Val Loss: 2.0029\n",
      "Epoch 16 -- Train Loss: 2.0290 -- Val Loss: 2.0256\n",
      "Epoch 17 -- Train Loss: 2.0340 -- Val Loss: 2.0390\n",
      "Epoch 18 -- Train Loss: 2.0254 -- Val Loss: 2.0685\n",
      "Epoch 19 -- Train Loss: 2.0273 -- Val Loss: 2.0392\n",
      "Epoch 20 -- Train Loss: 2.0228 -- Val Loss: 2.0361\n",
      "Epoch 21 -- Train Loss: 2.0200 -- Val Loss: 2.0305\n",
      "Epoch 22 -- Train Loss: 2.0161 -- Val Loss: 2.0949\n",
      "Epoch 23 -- Train Loss: 2.0238 -- Val Loss: 2.0571\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(prediction, target) \n\u001b[1;32m     13\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m e_optim\u001b[38;5;241m.\u001b[39mstep(), d_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m e_optim\u001b[38;5;241m.\u001b[39mzero_grad(), d_optim\u001b[38;5;241m.\u001b[39mzero_grad() \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30 \n",
    "\n",
    "for epoch in tqdm(range(1, NUM_EPOCHS +1), total=NUM_EPOCHS) : \n",
    "    train_loss = 0 \n",
    "    val_loss = 0\n",
    "    encoder.train(), decoder.train()\n",
    "    for input, target in train_loader :\n",
    "        input, target = input.to(device), target.to(device) \n",
    "        memory = encoder(input) \n",
    "        prediction = decoder(memory, None)\n",
    "\n",
    "        loss = loss_fn(prediction, target) \n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        e_optim.step(), d_optim.step()\n",
    "        e_optim.zero_grad(), d_optim.zero_grad() \n",
    "\n",
    "    encoder.eval(), decoder.eval()\n",
    "    with torch.no_grad() :\n",
    "        for input, target in val_loader :\n",
    "            input, target = input.to(device), target.to(device) \n",
    "            memory = encoder(input) \n",
    "            prediction = decoder(memory, None)\n",
    "\n",
    "            loss = loss_fn(prediction, target) \n",
    "            val_loss += loss.item()\n",
    "    print(f'Epoch {epoch} -- Train Loss: {train_loss / len(train_loader):.4f} -- Val Loss: {val_loss / len(val_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
